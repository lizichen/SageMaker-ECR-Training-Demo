{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Workflow\n",
    "Run through the notebook to:\n",
    "- build dummy train-able image\n",
    "- push to aws ecr\n",
    "- create dummy data and upload to s3\n",
    "- train with aws sagemaker\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "# from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the execution account and roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349934695336\n",
      "us-west-2\n",
      "arn:aws:iam::349934695336:role/basic-sagemaker-role\n",
      "sagemaker-us-west-2-349934695336\n"
     ]
    }
   ],
   "source": [
    "# no need to create one if the repo does not exist.\n",
    "#     349934695336.dkr.ecr.us-west-2.amazonaws.com/basic-sagemaker-train\n",
    "ecr_namespace = '349934695336.dkr.ecr.us-west-2.amazonaws.com/'\n",
    "prefix = 'basic-sagemaker-train' # sagemaker training job prefix\n",
    "ecr_repository_name = 'basic-sagemaker-train'\n",
    "\n",
    "#role arn: arn:aws:iam::349934695336:role/basic-sagemaker-role\n",
    "role = 'arn:aws:iam::349934695336:role/basic-sagemaker-role'\n",
    "account_id = role.split(':')[4]  #349934695336\n",
    "region = 'us-west-2'\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the train-able dummy image and push to ECR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print Dockerfile\n",
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mACCOUNT_ID\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\r\n",
      "\u001b[31mREGION\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\r\n",
      "\u001b[31mREPO_NAME\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\r\n",
      "\r\n",
      "docker build -f ../docker/Dockerfile -t \u001b[31m$REPO_NAME\u001b[39;49;00m ../docker\r\n",
      "\r\n",
      "docker tag \u001b[31m$REPO_NAME\u001b[39;49;00m \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\r\n",
      "\r\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --no-include-email --registry-ids \u001b[31m$ACCOUNT_ID\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m\r\n",
      "\r\n",
      "aws ecr describe-repositories --repository-names \u001b[31m$REPO_NAME\u001b[39;49;00m || aws ecr create-repository --repository-name \u001b[31m$REPO_NAME\u001b[39;49;00m\r\n",
      "\r\n",
      "docker push \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\r\n"
     ]
    }
   ],
   "source": [
    "# print build and push script:\n",
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-349934695336/basic-sagemaker-train/train/dummy.csv\n",
      "s3://sagemaker-us-west-2-349934695336/basic-sagemaker-train/val/dummy.csv\n"
     ]
    }
   ],
   "source": [
    "# We upload some dummy data to Amazon S3, in order to define our S3-based training channels.\n",
    "! echo \"val1, val2, val3\" > dummy.csv\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/train'))\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/val'))\n",
    "# remove after upload\n",
    "! rm dummy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349934695336.dkr.ecr.us-west-2.amazonaws.com/basic-sagemaker-train:latest\n"
     ]
    }
   ],
   "source": [
    "# Training with SageMaker requires the ECR path of the training image.\n",
    "image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sagemaker.estimator.Estimator(image_uri,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.set_hyperparameters(hp1='value1',\n",
    "                        hp2=300,\n",
    "                        hp3=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-08 07:30:20 Starting - Starting the training job...\n",
      "2020-09-08 07:30:22 Starting - Launching requested ML instances......\n",
      "2020-09-08 07:31:48 Starting - Preparing the instances for training......\n",
      "2020-09-08 07:32:45 Downloading - Downloading input data\n",
      "2020-09-08 07:32:45 Training - Downloading the training image...\n",
      "2020-09-08 07:33:24 Training - Training image download completed. Training in progress................\n",
      "2020-09-08 07:35:56 Uploading - Uploading generated training model.\u001b[34mRunning training...\n",
      "\u001b[0m\n",
      "\u001b[34mHyperparameters configuration:\u001b[0m\n",
      "\u001b[34m{'hp1': 'value1', 'hp2': '300', 'hp3': '0.001'}\n",
      "\u001b[0m\n",
      "\u001b[34mInput data configuration:\u001b[0m\n",
      "\u001b[34m{'train': {'ContentType': 'text/csv',\n",
      "           'RecordWrapperType': 'None',\n",
      "           'S3DistributionType': 'FullyReplicated',\n",
      "           'TrainingInputMode': 'File'},\n",
      " 'validation': {'ContentType': 'text/csv',\n",
      "                'RecordWrapperType': 'None',\n",
      "                'S3DistributionType': 'FullyReplicated',\n",
      "                'TrainingInputMode': 'File'}}\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[34mResource configuration:\u001b[0m\n",
      "\u001b[34m{'current_host': 'algo-1',\n",
      " 'hosts': ['algo-1'],\n",
      " 'network_interface_name': 'eth0'}\n",
      "\u001b[0m\n",
      "\u001b[34mTraining job name: \u001b[0m\n",
      "\u001b[34mbasic-sagemaker-train-2020-09-08-07-30-20-082\n",
      "\u001b[0m\n",
      "\u001b[34mTraining job ARN: \u001b[0m\n",
      "\u001b[34marn:aws:sagemaker:us-west-2:349934695336:training-job/basic-sagemaker-train-2020-09-08-07-30-20-082\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 0...\u001b[0m\n",
      "\u001b[34mCompleted epoch 0.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 1...\u001b[0m\n",
      "\u001b[34mCompleted epoch 1.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 2...\u001b[0m\n",
      "\u001b[34mCompleted epoch 2.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 3...\u001b[0m\n",
      "\u001b[34mCompleted epoch 3.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 4...\u001b[0m\n",
      "\u001b[34mCompleted epoch 4.\n",
      "\u001b[0m\n",
      "\u001b[34mTraining completed!\u001b[0m\n",
      "\n",
      "2020-09-08 07:36:02 Completed - Training job completed\n",
      "Training seconds: 203\n",
      "Billable seconds: 203\n"
     ]
    }
   ],
   "source": [
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
